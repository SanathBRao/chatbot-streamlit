import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from PIL import Image
from io import BytesIO
import google.generativeai as genai
import base64
import os

# --- Set up API key securely ---
os.environ["GOOGLE_API_KEY"] = st.secrets["GOOGLE_API_KEY"]
genai.configure(api_key=os.environ["GOOGLE_API_KEY"])

# --- Streamlit page config ---
st.set_page_config(page_title="Gemini Chatbot + Image Generator", layout="centered")
st.title("ü§ñ Gemini Chatbot + üé® Image Generator")

# --- Initialize Gemini Chatbot model ---
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

# --- Initialize chat history ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [SystemMessage(content="You are a helpful assistant.")]

# --- Display chat history ---
for msg in st.session_state.chat_history:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    if isinstance(msg, (HumanMessage, AIMessage)):
        with st.chat_message(role):
            st.markdown(msg.content)

# --- Chat input ---
user_input = st.chat_input("Type your message...")

if user_input:
    st.session_state.chat_history.append(HumanMessage(content=user_input))

    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = llm.invoke(st.session_state.chat_history)
            st.markdown(response.content)

    st.session_state.chat_history.append(AIMessage(content=response.content))

# --- Image generation section ---
st.subheader("üñºÔ∏è Generate Image from Prompt")

image_prompt = st.text_area("Enter prompt for image generation", placeholder="e.g. Virat Kohli lifts IPL trophy")

if st.button("Generate Image"):
    if not image_prompt.strip():
        st.warning("Please enter a valid prompt.")
    else:
        with st.spinner("Generating image using Gemini..."):
            try:
                model = genai.GenerativeModel(model_name="models/gemini-2.0-flash-preview-image-generation")
                response = model.generate_content(
                    contents=[{"text": image_prompt}],
                    config={
                        "response_modalities": ["TEXT", "IMAGE"]
                    }
                )

                text_response = ""
                images = []

                for part in response.candidates[0].content.parts:
                    if hasattr(part, "text") and part.text:
                        text_response += part.text + "\n"
                    elif hasattr(part, "inline_data") and part.inline_data.data:
                        image_data = base64.b64decode(part.inline_data.data)
                        image = Image.open(BytesIO(image_data))
                        images.append(image)

                if text_response:
                    st.subheader("Text Response")
                    st.write(text_response.strip())

                if images:
                    st.subheader("Generated Image(s)")
                    for img in images:
                        st.image(img, caption="Generated by Gemini", use_column_width=True)

            except Exception as e:
                st.error(f"‚ùå Error generating content: {e}")
