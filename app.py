import streamlit as st
from PIL import Image
from io import BytesIO
import base64
import google.generativeai as genai
import os

# Configure API key
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
genai.configure(api_key=GOOGLE_API_KEY)

st.set_page_config(page_title="Gemini Chatbot + Image Generator", layout="centered")
st.title("ğŸ¤– Gemini Chatbot + ğŸ¨ Image Generator")

# --- Gemini Chatbot initialization ---
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

# Add temperature slider
temperature = st.slider("Chatbot Temperature", min_value=0.0, max_value=1.0, value=0.7, step=0.01)
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=temperature)

# Chat session state
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [SystemMessage(content="You are a helpful assistant.")]

# Show chat messages
for msg in st.session_state.chat_history:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    if isinstance(msg, (HumanMessage, AIMessage)):
        with st.chat_message(role):
            st.markdown(msg.content)

user_input = st.chat_input("Type your message...")

if user_input:
    st.session_state.chat_history.append(HumanMessage(content=user_input))
    with st.chat_message("user"):
        st.markdown(user_input)
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = llm.invoke(st.session_state.chat_history)
            st.markdown(response.content)
    st.session_state.chat_history.append(AIMessage(content=response.content))

st.divider()

# --- Image + text generation using genai.generate_content() ---

st.subheader("ğŸ–¼ï¸ Generate Image + Text using Gemini")
image_prompt = st.text_area("Enter image prompt", placeholder="e.g. Virat Kohli lifts IPL trophy")

# Add temperature slider for image generation (if applicable to the model)
image_temperature = st.slider("Image Temperature", min_value=0.0, max_value=1.0, value=0.7, step=0.01)


if st.button("Generate Image"):
    if not image_prompt.strip():
        st.warning("Please enter a valid prompt.")
    else:
        with st.spinner("Generating content with Gemini..."):
            try:
                response = genai.generate_content(
                    model="models/gemini-2.0-flash-preview-image-generation",
                    contents=[{"text": image_prompt}],
                    response_modalities=["TEXT", "IMAGE"],
                    generation_config={"temperature": image_temperature} # Add temperature here if supported
                )

                for part in response.candidates[0].content.parts:
                    if hasattr(part, "text") and part.text:
                        st.subheader("Text Response")
                        st.write(part.text)

                    elif hasattr(part, "inline_data") and part.inline_data:
                        image_data_base64 = part.inline_data.data
                        image_bytes = base64.b64decode(image_data_base64)
                        image = Image.open(BytesIO(image_bytes))
                        st.subheader("Generated Image")
                        st.image(image, caption="Generated by Gemini", use_column_width=True)

            except Exception as e:
                st.error(f"âŒ Error generating content: {e}")import streamlit as st
from PIL import Image
from io import BytesIO
import base64
import google.generativeai as genai
import os

# Configure API key
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
genai.configure(api_key=GOOGLE_API_KEY)

st.set_page_config(page_title="Gemini Chatbot + Image Generator", layout="centered")
st.title("ğŸ¤– Gemini Chatbot + ğŸ¨ Image Generator")

# --- Gemini Chatbot initialization ---
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage

# Add temperature slider
temperature = st.slider("Chatbot Temperature", min_value=0.0, max_value=1.0, value=0.7, step=0.01)
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=temperature)

# Chat session state
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [SystemMessage(content="You are a helpful assistant.")]

# Show chat messages
for msg in st.session_state.chat_history:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    if isinstance(msg, (HumanMessage, AIMessage)):
        with st.chat_message(role):
            st.markdown(msg.content)

user_input = st.chat_input("Type your message...")

if user_input:
    st.session_state.chat_history.append(HumanMessage(content=user_input))
    with st.chat_message("user"):
        st.markdown(user_input)
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = llm.invoke(st.session_state.chat_history)
            st.markdown(response.content)
    st.session_state.chat_history.append(AIMessage(content=response.content))

st.divider()

# --- Image + text generation using genai.generate_content() ---

st.subheader("ğŸ–¼ï¸ Generate Image + Text using Gemini")
image_prompt = st.text_area("Enter image prompt", placeholder="e.g. Virat Kohli lifts IPL trophy")

# Add temperature slider for image generation (if applicable to the model)
image_temperature = st.slider("Image Temperature", min_value=0.0, max_value=1.0, value=0.7, step=0.01)


if st.button("Generate Image"):
    if not image_prompt.strip():
        st.warning("Please enter a valid prompt.")
    else:
        with st.spinner("Generating content with Gemini..."):
            try:
                response = genai.generate_content(
                    model="models/gemini-2.0-flash-preview-image-generation",
                    contents=[{"text": image_prompt}],
                    response_modalities=["TEXT", "IMAGE"],
                    generation_config={"temperature": image_temperature} # Add temperature here if supported
                )

                for part in response.candidates[0].content.parts:
                    if hasattr(part, "text") and part.text:
                        st.subheader("Text Response")
                        st.write(part.text)

                    elif hasattr(part, "inline_data") and part.inline_data:
                        image_data_base64 = part.inline_data.data
                        image_bytes = base64.b64decode(image_data_base64)
                        image = Image.open(BytesIO(image_bytes))
                        st.subheader("Generated Image")
                        st.image(image, caption="Generated by Gemini", use_column_width=True)

            except Exception as e:
                st.error(f"âŒ Error generating content: {e}")
