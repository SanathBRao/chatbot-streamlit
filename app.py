import streamlit as st
from PIL import Image
from io import BytesIO
import base64
import google.generativeai as genai
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
import os

# --- Configure API key ---
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
genai.configure(api_key=GOOGLE_API_KEY)

# --- Streamlit page config ---
st.set_page_config(page_title="Gemini Chatbot + Image Generator", layout="centered")
st.title("ü§ñ Gemini Chatbot + üé® Image Generator")

# --- Initialize Gemini chatbot model ---
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

# --- Initialize chat history in session ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [SystemMessage(content="You are a helpful assistant.")]

# --- Display chat history ---
for msg in st.session_state.chat_history:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    if isinstance(msg, (HumanMessage, AIMessage)):
        with st.chat_message(role):
            st.markdown(msg.content)

# --- Chat input ---
user_input = st.chat_input("Type your message...")

if user_input:
    # Add user message
    st.session_state.chat_history.append(HumanMessage(content=user_input))
    with st.chat_message("user"):
        st.markdown(user_input)

    # Generate chatbot response
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = llm.invoke(st.session_state.chat_history)
            st.markdown(response.content)
    # Save assistant response
    st.session_state.chat_history.append(AIMessage(content=response.content))

st.divider()

# --- Image generation section ---
st.subheader("üñºÔ∏è Generate Image + Text using Gemini")

image_prompt = st.text_area("Enter image prompt", placeholder="e.g. Virat Kohli lifts IPL trophy")

if st.button("Generate Image"):
    if not image_prompt.strip():
        st.warning("Please enter a valid prompt.")
    else:
        with st.spinner("Generating content with Gemini..."):
            try:
                # Use Gemini preview image generation model
                model = genai.GenerativeModel(model_name="gemini-2.0-flash-preview-image-generation")

                response = model.generate_content(
                    contents=[{"text": image_prompt}],
                    response_modalities=["TEXT", "IMAGE"]
                )

                # Parse response parts
                for part in response.candidates[0].content.parts:
                    if hasattr(part, "text") and part.text:
                        st.subheader("Text Response")
                        st.write(part.text)

                    elif hasattr(part, "inline_data") and part.inline_data:
                        # inline_data.data is base64-encoded image string
                        image_data_base64 = part.inline_data.data
                        image_bytes = base64.b64decode(image_data_base64)
                        image = Image.open(BytesIO(image_bytes))
                        st.subheader("Generated Image")
                        st.image(image, caption="Generated by Gemini", use_column_width=True)

            except Exception as e:
                st.error(f"‚ùå Error generating content: {e}")
